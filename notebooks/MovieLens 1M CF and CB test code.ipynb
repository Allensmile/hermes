{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the RMSE for the MovieLens 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from math import sqrt\n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.addPyFile('hermes.zip')\n",
    "from src.algorithms import cf\n",
    "from src.algorithms import performance_metrics\n",
    "from src.data_prep import movieLens_vectorize as mv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.algorithms import content_based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Bring in data and create a user vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = sqlCtx.read.json(\n",
    "    'movielens/1m/movielens_1m_movies.json.gz',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = sqlCtx.read.json('movielens/1m/movielens_1m_ratings.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up the vectorizer\n",
    "mv_vect = mv.movieLens_vectorize(ratings, movies, 'ratings', 'genre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the user vector\n",
    "all_user_ratings = mv_vect.get_user_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1193, 5.0),\n",
       " (1, 661, 3.0),\n",
       " (1, 914, 3.0),\n",
       " (1, 3408, 4.0),\n",
       " (1, 2355, 5.0),\n",
       " (1, 1197, 3.0),\n",
       " (1, 1287, 5.0),\n",
       " (1, 2804, 5.0),\n",
       " (1, 594, 4.0),\n",
       " (1, 919, 4.0)]"
      ]
     },
     "execution_count": 8,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "all_user_ratings.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train, test\n",
    "train_ratings, test_ratings = all_user_ratings.randomSplit([90,10], 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 900025 100184\n"
     ]
    }
   ],
   "source": [
    "print train_ratings.count(), test_ratings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predicted locations\n",
    "predicted = cf.calc_cf_mllib(train_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.884895332015\n"
     ]
    }
   ],
   "source": [
    "#run a performance metric\n",
    "rmse = performance_metrics.calculate_rmse_using_rdd(test_ratings, predicted)\n",
    "print rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##What do all the RDDs looks like you may ask?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "[(1, 1193, 5.0), (1, 661, 3.0), (1, 914, 3.0), (1, 3408, 4.0), (1, 2355, 5.0)]\n"
     ]
    }
   ],
   "source": [
    "print type(all_user_ratings)\n",
    "print all_user_ratings.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.RDD'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Rating(user=4904, product=3456, rating=4.074128624320234),\n",
       " Rating(user=3456, product=3456, rating=2.560508811974863),\n",
       " Rating(user=3272, product=3456, rating=3.0780781662221983),\n",
       " Rating(user=752, product=3456, rating=6.015084508693184),\n",
       " Rating(user=4352, product=3456, rating=6.613422183304756)]"
      ]
     },
     "execution_count": 14,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "print type(predicted)\n",
    "predicted.take(5)  \n",
    "#our predicted vectors don't need the fancy labels, (though we could use NamedTuples)\n",
    "#the prediction functions work on either :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##So this works for CF, what does content based look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_content_vector = mv_vect.get_content_vector().repartition(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, array([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       " (2, array([0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       " (3, array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0])),\n",
       " (4, array([0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])),\n",
       " (5, array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))]"
      ]
     },
     "execution_count": 14,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "movie_content_vector.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the predicted locations\n",
    "predicted_2 = content_based.predict(train_ratings, movie_content_vector, max_prediction=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.42863242792\n"
     ]
    }
   ],
   "source": [
    "#run a performance metric\n",
    "rmse = performance_metrics.calculate_rmse_using_rdd(test_ratings, predicted_2)\n",
    "print rmse"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "#So the RMSE for the CF algorithm had better accuracy than the content based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5661, 1, 3.5000000000000004),\n",
       " (5151, 1, 3.3509189925119127),\n",
       " (4641, 1, 3.4479237576582706),\n",
       " (4131, 1, 3.296014729464869),\n",
       " (3621, 1, 3.1900915871237006)]"
      ]
     },
     "execution_count": 17,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "#what do these predictions look like?\n",
    "print type(predicted_2)\n",
    "predicted_2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}